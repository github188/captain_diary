http://blog.csdn.net/ty4315/article/details/52216135  这个系列博客不错


1.   yum  -y install java-openjdk*

2. wget  https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.4.4.tar.gz

3.mv elasticsearch-1.4.4 /usr/local/

4 cd /usr/local
5. tar -zxvf elasticsearch-1.4.4

6.  cd elasticsearch-1.4.4/bin

7. sh elasticsearch-1.4.4 

xshell复制一个会话出来，继续  
Put创建索引
curl -X PUT http://localhost:9200/shb01/student/1 -d '{"name":"jack","age":30,"info":"Ilove you"}'

返回  {"_index":"shb02","_type":"student","_id":"1","_version":5,"created":false} 多执行几次，每次version都会加1  id没有变化，说明
put是幂等操作，也就是如果存在该id的数据，那么就修改这条数据，如果不存在，就创建这条数据。

执行put后有返回值

_index索引名称

_type类型名

_version版本号

created:true表示是新创建的。

上面的命令每执行一次version就会加1，-XPUT必须制定id
POST创建索引
curl -X POST http://localhost:9200/shb01/student -d '{"name":"tom","age":21,"info":"tom"}'

Post创建索引

curl -XPOST http://localhost:9200/shb01/student -d '{"name":"tom","age":21,"info":"tom"}'

{"_index":"shb01","_type":"student","_id":"AVadzuNgxskBS1Rg2tdp","_version":1,"created":true}

使用post创建索引数据，-XPOST可以指定id，此时如果存在相同数据则是修改，不指定id的话会随机生成id，且每次执行都会生成新数据。

 

如果需要每次执行都产生新的数据可以使用post命令且不指定id。

如果使用put命令则需要增加create，命令格式如下

curl -XPUT http://localhost:9200/shb01/student/1/_create -d '{"name":"jackk","age":31}'

curl -XPUT http://localhost:9200/shb01/student/1?op_type=create -d '{"name":"jackk","age":31}'

以上两条命令执行时如果存在id相同的数据则会给出error信息

{"error":"DocumentAlreadyExistsException[[shb01][2][student][1]: document already exists]","status":409}

 

Post与put的区别

Put是等幂操作，即无论执行多少次结果都一样，例如DEL无论删除多少次索引库中的结果都一样，put只要指定了id且数据不变无论执行多少次索引库中的数据都不变，
只有version会变化。

Post每次执行都会产生新数据。 post 相同id的数据会强行覆盖 put则会报错，提示该id数据已存在

查询

1：查询索引库shb01中的类型student

浏览器：http://192.168.79.131:9200/shb01/student/_search?pretty   查询shb01库下面的student表   
http://123.207.56.239:9200/shb01/_search?pretty   查询shb01下面的所有数据
http://123.207.56.239:9200/_search?pretty   查询这个es存储的所有数据

2：查询文档1中的数据

http://192.168.79.131:9200/shb01/student/1?pretty

http://192.168.79.131:9200/shb01/student/1?_source&pretty
http://192.168.79.131:9200/shb01/student/1?_source=name&pretty

注意：这种写法是错误的  http://123.207.56.239:9200/shb01/student/1/_search?pretty   /_search是多余的

可以通过source指定显示那些字段

3：查询所有索引库信息

浏览器：http://192.168.79.131:9200/_search?pretty

4：根据条件查询

浏览器：http://192.168.79.131:9200/shb01/student/_search?q=name:zs&pretty

查询name为zs的数据

5：查询集群状态

Curl –XGET http://192.168.79.131:9200/_cluster/health?pretty

http://192.168.79.131:9200/_cluster/health?pretty

6：多索引，多类型查询,分页查询,超时

Curl：curl -XGET http://192.168.79.131:9200/shb01,shb02/stu,tea/_search?pretty

curl -XGET http://192.168.79.131:9200/_all/stu,tea/_search?pretty

浏览器去掉curl –XGET即可

分页

curl -XGET http://192.168.79.131:9200/shb01/stu/_search?size=2&from=0

超时

     curl -XPOST http://192.168.79.131:9200/_search?_timeout=100




更新

Es

部分更新

如果文档1的字段很多而我们只需要更新其中的一两个字段则可以通过doc指定需要修改的字段其他字段则不必修改。

crul –XPUT

http:192.168.79.131:9200/shb01/student/1/_update?version=1

 –d ‘{“doc”:{“name”:”updatename”}’

 

全量更新：

    更新文档1中所有字段的内容。

curl -XPUThttp://192.168.79.131:9200/shb01/student/1 -d'{"name":"will","age":100,"info":"newonw"}'

 

更新流程

es会将旧的文档进行标记然后再添加新数据，旧的文档也不能再被访问，在后续添加数据时es会清理已经为删除状态的数据。

删除

删除文档并不会立即生效，只会将其标记为已删除，当后续添加更多索引时才会在后台删除。

curl -XDELETE http://192.168.79.131:9200/shb01/student/AVad05EExskBS1Rg2tdq

根据id删除，删除成功返回found:true，找不到found:false,版本号都会加1。



根据条件删除,删除索引shb01，shb02种类型student，tea中所有name为zs的文档

curl -XDELETEhttp://192.168.79.131:9200/shb01,shb02/student,tea/_query?q=name:zs



删除所有的索引库中名称为tom的文档

curl -XDELETE http://192.168.79.131:9200/_all/_query?q=name:tom

 

批处理

将一批数据加载入内存然后和es交互一次，一次性同时处理多个请求和redis的管道类似。

格式：

Action:index/create/delete/update

Metadata:_index/_type/_id

Create：如果数据存在则报错；index：如果数据存在仍会执行成功。

步骤：

1：在liunx下创建一个文件request1，vi request1

    {"index":{"_index":"shb01","_type":"student","_id":"1"}}

{"name":"st01","age":"10","info":"st01"}

{"create":{"_index":"shb100","_type":"student","_id":"2"}}

{"name":"tea01","age":"10","info":"tea01"}

{"delete":{"_index":"shb01","_type":"student","_id":"AVadzuNgxskBS1Rg2tdp"}

{"update":{"_index":"shb02","_type":"tea","_id":"1"}}

{"doc":{"name":"zszszszs"}}

 

文件中

index表示操作类型

_index指定索引库，_type指定类型，_id指定操作文档

 

 

2：执行批处理命令，关键字_bulk

curl  -XPUT http://192.168.79.131:9200/_bulk --data-binary @/usr/local/request1

注意：--data-binary@之间有空格隔开，我在实验中没有空格一直提示操作参数不对。

 

3：返回值

{

"took":957,"errors":false,"items":[

{"index":{"_index":"shb01","_type":"student","_id":"1","_version":12,"status":200}},

{"create":{"_index":"shb100","_type":"student","_id":"2","_version":1,"status":201}},

{"delete":{"_index":"shb01","_type":"student","_id":"AVadzuNgxskBS1Rg2tdp","_version":2,"status":200,"found":true}},

{"update":{"_index":"shb02","_type":"tea","_id":"1","_version":2,"status":200}}

]

 

返回信息中errors表示批处理有没有错误，注意version和status，其中shb100为新创建的索引库

下面是我第二次执行request1文件的返回信息，errors为true，表示批处理中有操作执行失败，可以看到create因为库中已有id相同的文档所以报错。但是虽然存在错误操作但其他的操作依然成功执行。这点和redis中的事务操作类似。

{

"took":22,"errors":true,"items":[

{"index":{"_index":"shb01","_type":"student","_id":"1","_version":13,"status":200}},

{"create":{"_index":"shb100","_type":"student","_id":"2","status":409,"error":"DocumentAlreadyExistsException[[shb100][3][student][2]: document already exists]"}},

{"delete":{"_index":"shb01","_type":"student","_id":"AVadzuNgxskBS1Rg2tdp","_version":1,"status":404,"found":false}},

{"update":{"_index":"shb02","_type":"tea","_id":"1","_version":3,"status":200}}

]

}

 

4：在命令中指定索引库和类型

创建一个文件，文件中没有配置索引库和类型

{"index":{"_id":"1"}}

{"name":"st1_1","age":"10","info":"st1_1"}

{"create":{"_id":"200"}}

{"name":"st200","age":"10","info":"st200"}

 

执行如下命令，在命令中指定了索引库和类型

curl  -XPUT http://192.168.79.131:9200/shb01/student/_bulk --data-binary@/usr/local/request2

 

返回信息

{

"took":24,"errors":false,"items":[

{"index":{"_index":"shb01","_type":"student","_id":"1","_version":17,"status":200}},

{"create":{"_index":"shb01","_type":"student","_id":"200","_version":1,"status":201}}

]

}

 

5：也可以使用-XPOST替换-XPUT


Elasticsearch笔记四之配置参数与核心概念
原创 2016年08月21日 21:35:58 标签：elasticsearch /配置参数 /核心概念 1220
      在es根目录下有一个config目录，在此目录下有两个文件分别是elasticsearch.yml和logging.yml。

      logging.yml是日志文件，es也是使用log4j来记录日志的，我在此文件中配置日志级别。

      elasticsearch.yml是es的基本配置文件es的参数都在这个文件中，我们这里结合此文件来介绍es的核心概念和参数。

1：集群

       node.master: true表示此节点有资格竞争成为主节点。

       cluster.name: elasticsearch表示es集群的名称可以自行更改

       discovery.zen.ping.multicast.enabled: false 集群的自动发现机制，false不启动

        discovery.zen.ping.unicast.hosts: ["host1","host2:port"] 告诉从节点主节点的位置，默认是9300端口。

 

        Es集群由多个节点组成，其中一个为主节点其他为从节点。从节点通过竞争来确定哪个是主节点，一般在集群中第一个启动的符合条件的就是主节点。主节点负责管理集群状态包括管理分片和副本的状态以及节点的增加和删除。

       Es集群具有去中心化的概念，我们可以访问集群中的任何一个节点来操作整个集群，不管它是主节点还是从节点只要安装了相关插件就行。

同一个网段内的es节点会自动互相感知自动组成集群。

 

        自动发现机制

        Es是基于P2P的系统，当集群启动后会先通过广播寻找存在的节点，再通过多播协议进行节点间的通信进而自动组建es集群，同时也支持节点之间的通信。

        同一网段内节点组建集群，首先启动自动发现机制另外节点的集群名称要一致

                 discovery.zen.ping.multicast.enabled: true

                 cluster.name: elasticsearch

       如果不同网段的节点要组建集群首先各个节点禁用自动发现机制然后给从节点指定主节点的位置，默认是9300端口。

                 discovery.zen.ping.multicast.enabled: false

                 discovery.zen.ping.unicast.hosts: ["host1","host2:port"]

       

         查看集群状态

         浏览器：http://192.168.79.131:9200/_cluster/health?pretty

{

  "cluster_name" :"shb01",

  "status" :"green",

  "timed_out" :false,

  "number_of_nodes": 1,

 "number_of_data_nodes" : 1,

 "active_primary_shards" : 0,

  "active_shards" :0,

 "relocating_shards" : 0,

 "initializing_shards" : 0,

 "unassigned_shards" : 0

}

2：shards分片

     index.number_of_shards: 5 分片数

     Es中索引库会被拆分成多个分片，各个分片会存储在不同的节点上以提高集群的存储能力从而构成分布式的存储和分布式的查询。

     通过index.number_of_shards参数指定分片数默认是5,分片数一旦指定集群启动后不能动态的修改。

3：replicas副本

        index.number_of_replicas：1副本数，默认为1

        当某个节点宕机或被删除后可以通过副本进行恢复，另外也可以提高查询效率分流查询实现负载均衡。分片和其副本不会被存储与同一个节点上，如果只有一个节点则没有副本。

4：持久化方式

        gateway.type:local

        索引的持久化方式默认是local本地方式，也可以存放在hdfs中。

        /usr/local/elasticsearch-1.4.4/data/elasticsearch/nodes/0/indices/shb01/0

        第一个0表示集群中的节点编号，最后一个0表示分片。我的节点上一共有0到4，共5个分片。

5：transport

        交互方式，es集群与客户端使用tcp协议交互同时也支持http协议

        transport.tcp.port: 9300   节点之间通信使用此端口

        http.port: 9200    http请求使用9200端口

        我们在启动es时可以看到es在监控这两个节点

6：recovery

        数据恢复与重新分布，当有节点加入或退出时es会根据机器的负载对索引分片进行重新分配，挂了的节点在重启后也会进行恢复。

7：其他参数

        node.data: true 为true表示此节点可以用来存储数据。默认true

        http.enabled: false 默认不禁用http访问

        http.max_content_length: 100mb 限制_bulk批处理的最大数据量。

        bootstrap.mlockall: true  禁用内存交互

Elasticsearch笔记五之java操作es
原创 2016年09月04日 19:50:22 标签：java /elasticsearch 29891
Java操作es集群步骤1：配置集群对象信息；2：创建客户端；3：查看集群信息

1：集群名称

      默认集群名为elasticsearch，如果集群名称和指定的不一致则在使用节点资源时会报错。

2：嗅探功能

       通过client.transport.sniff启动嗅探功能，这样只需要指定集群中的某一个节点(不一定是主节点)，然后会加载集群中的其他节点，这样只要程序不停即使此节点宕机仍然可以连接到其他节点。

3：查询类型SearchType.QUERY_THEN_FETCH

      Es中一共有四种查询类型。

      QUERY_AND_FETCH：

      主节点将查询请求分发到所有的分片中，各个分片按照自己的查询规则即词频文档频率进行打分排序，然后将结果返回给主节点，主节点对所有数据进行汇总排序然后再返回给客户端，此种方式只需要和es交互一次。

      这种查询方式存在数据量和排序问题，主节点会汇总所有分片返回的数据这样数据量会比较大，二是各个分片上的规则可能不一致。

QUERY_THEN_FETCH：

      主节点将请求分发给所有分片，各个分片打分排序后将数据的id和分值返回给主节点，主节点收到后进行汇总排序再根据排序后的id到对应的节点读取对应的数据再返回给客户端，此种方式需要和es交互两次。

      这种方式解决了数据量问题但是排序问题依然存在而且是es的默认查询方式。

DFS_QUERY_AND_FETCH和DFS_QUERY_THEN_FETCH：

      这两种方式和前面两种的区别在于将各个分片的规则统一起来进行打分。解决了排序问题但是DFS_QUERY_AND_FETCH仍然存在数据量问题，DFS_QUERY_THEN_FETCH两种噢乖你问题都解决但是效率是最差的。

特点：

     一个交互两次，一个交互一次；一个统一打分规则一个不统一；一个分片返回详细数据一个分片返回id。

4：分页压力

       我们通过curl和java查询时都可以指定分页，但是页数越往后服务器的压力会越大。大多数搜索引擎都不会提供非常大的页数搜索，原因有两个一是用户习惯一般不会看页数大的搜索结果因为越往后越不准确，二是服务器压力。

       比如分片是5分页单位是10查询第10000到10010条记录，es需要在所有分片上进行查询，每个分片会产生10010条排序后的数据然后返回给主节点，主节点接收5个分片的数据一共是50050条然后再进行汇总最后再取其中的10000到10010条数据返回给客户端，这样一来看似只请求了10条数据但实际上es要汇总5万多条数据，所以页码越大服务器的压力就越大。

5：超时timeout

       查询时如果数据量很大，可以指定超时时间即到达此时间后无论查询的结果是什么都会返回并且关闭连接，这样用户体验较好缺点是查询出的数据可能不完整，Java和curl都可以指定超时时间。

6：maven依赖

[java] view plain copy
<dependency>  
            <groupId>org.elasticsearch</groupId>  
            <artifactId>elasticsearch</artifactId>  
            <version>1.4.4</version>  
        </dependency>    
        <dependency>  
            <groupId>com.fasterxml.jackson.core</groupId>  
            <artifactId>jackson-databind</artifactId>  
            <version>2.1.3</version>  
        </dependency>  


以下是java代码
``` java 
package elasticsearch;

import java.io.IOException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ExecutionException;

import online.elasticsearch.bean.Student;

import org.elasticsearch.ElasticsearchException;
import org.elasticsearch.action.bulk.BulkItemResponse;
import org.elasticsearch.action.bulk.BulkRequestBuilder;
import org.elasticsearch.action.bulk.BulkResponse;
import org.elasticsearch.action.delete.DeleteRequest;
import org.elasticsearch.action.delete.DeleteResponse;
import org.elasticsearch.action.get.GetResponse;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.action.search.SearchType;
import org.elasticsearch.action.update.UpdateRequest;
import org.elasticsearch.action.update.UpdateResponse;
import org.elasticsearch.client.transport.TransportClient;
import org.elasticsearch.cluster.node.DiscoveryNode;
import org.elasticsearch.common.collect.ImmutableList;
import org.elasticsearch.common.settings.ImmutableSettings;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.text.Text;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import org.elasticsearch.common.transport.TransportAddress;
import org.elasticsearch.common.xcontent.XContentBuilder;
import org.elasticsearch.common.xcontent.XContentFactory;
import org.elasticsearch.index.query.FilterBuilders;
import org.elasticsearch.index.query.MatchQueryBuilder.Operator;
import org.elasticsearch.index.query.QueryBuilders;
import org.elasticsearch.search.SearchHit;
import org.elasticsearch.search.SearchHits;
import org.elasticsearch.search.aggregations.Aggregation;
import org.elasticsearch.search.aggregations.AggregationBuilders;
import org.elasticsearch.search.aggregations.Aggregations;
import org.elasticsearch.search.aggregations.bucket.terms.Terms;
import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;
import org.elasticsearch.search.aggregations.metrics.sum.Sum;
import org.elasticsearch.search.highlight.HighlightField;
import org.elasticsearch.search.sort.SortOrder;
import org.junit.Before;
import org.junit.Test;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

public class elastaicTest {

	TransportClient transportClient;
	//索引库名
	String index = "shb01";
	//类型名称
	String type = "stu";
	
	@Before
	public void before()
	{
		/**
		 * 1:通过 setting对象来指定集群配置信息
		 */
		Settings setting = ImmutableSettings.settingsBuilder()
			.put("cluster.name", "shb01")//指定集群名称
			.put("client.transport.sniff", true)//启动嗅探功能
			.build();
		
		/**
		 * 2：创建客户端
		 * 通过setting来创建，若不指定则默认链接的集群名为elasticsearch
		 * 链接使用tcp协议即9300
		 */
		transportClient = new TransportClient(setting);                        
		TransportAddress transportAddress = new InetSocketTransportAddress("192.168.79.131", 9300);
		transportClient.addTransportAddresses(transportAddress);
		
		/**
		 * 3：查看集群信息
		 * 注意我的集群结构是：
		 *   131的elasticsearch.yml中指定为主节点不能存储数据，
		 *   128的elasticsearch.yml中指定不为主节点只能存储数据。
		 * 所有控制台只打印了192.168.79.128,只能获取数据节点
		 * 
		 */
	    ImmutableList<DiscoveryNode> connectedNodes = transportClient.connectedNodes();
	    for(DiscoveryNode node : connectedNodes)
	    {
	    	System.out.println(node.getHostAddress());
	    }
	    
	}
	
	/**
	 * 通过prepareGet方法获取指定文档信息
	 */
	@Test
	public void testGet() {
		GetResponse getResponse = transportClient.prepareGet(index, type, "1").get();
		System.out.println(getResponse.getSourceAsString());
	}
	
	/**
	 * prepareUpdate更新索引库中文档，如果文档不存在则会报错
	 * @throws IOException
	 * 
	 */
	@Test
	public void testUpdate() throws IOException
	{
		XContentBuilder source = XContentFactory.jsonBuilder()
			.startObject()
			.field("name", "will")
			.endObject();
		
		UpdateResponse updateResponse = transportClient
				.prepareUpdate(index, type, "6").setDoc(source).get();
		
		System.out.println(updateResponse.getVersion());
	}

	/**
	 * 通过prepareIndex增加文档，参数为json字符串
	 */
	@Test
	public void testIndexJson()
	{
		String source = "{\"name\":\"will\",\"age\":18}";
		IndexResponse indexResponse = transportClient
				.prepareIndex(index, type, "3").setSource(source).get();
		System.out.println(indexResponse.getVersion());
	}
	
	/**
	 * 通过prepareIndex增加文档，参数为Map<String,Object>
	 */
	@Test
	public void testIndexMap()
	{
		Map<String, Object> source = new HashMap<String, Object>(2);
		source.put("name", "Alice");
		source.put("age", 16);
		IndexResponse indexResponse = transportClient
				.prepareIndex(index, type, "4").setSource(source).get();
		System.out.println(indexResponse.getVersion());
	}
	
	/**
	 * 通过prepareIndex增加文档，参数为javaBean
	 * 
	 * @throws ElasticsearchException
	 * @throws JsonProcessingException
	 */
	@Test
	public void testIndexBean() throws ElasticsearchException, JsonProcessingException
	{
		Student stu = new Student();
		stu.setName("Fresh");
		stu.setAge(22);
		
		ObjectMapper mapper = new ObjectMapper();
		IndexResponse indexResponse = transportClient
				.prepareIndex(index, type, "5").setSource(mapper.writeValueAsString(stu)).get();
		System.out.println(indexResponse.getVersion());
	}
	
	/**
	 * 通过prepareIndex增加文档，参数为XContentBuilder
	 * 
	 * @throws IOException
	 * @throws InterruptedException
	 * @throws ExecutionException
	 */
	@Test
	public void testIndexXContentBuilder() throws IOException, InterruptedException, ExecutionException
	{
		XContentBuilder builder = XContentFactory.jsonBuilder()
				.startObject()
				.field("name", "Avivi")
				.field("age", 30)
				.endObject();
		IndexResponse indexResponse = transportClient
				.prepareIndex(index, type, "6")
				.setSource(builder)
				.execute().get();
		//.execute().get();和get()效果一样
		System.out.println(indexResponse.getVersion());
	}
	
	/**
	 * 通过prepareDelete删除文档
	 * 
	 */
	@Test
	public void testDelete()
	{
		String id = "9";
		DeleteResponse deleteResponse = transportClient.prepareDelete(index,
				type, id).get();
		
		System.out.println(deleteResponse.getVersion());
		
		//删除所有记录
		transportClient.prepareDeleteByQuery(index).setTypes(type)
				.setQuery(QueryBuilders.matchAllQuery()).get();
	}
	
	/**
	 * 删除索引库，不可逆慎用
	 */
	@Test
	public void testDeleteeIndex()
	{
		transportClient.admin().indices().prepareDelete("shb01","shb02").get();
	}
	
	/**
	 * 求索引库文档总数
	 */
	@Test
	public void testCount()
	{
		long count = transportClient.prepareCount(index).get().getCount();
		System.out.println(count);
	}
	
	/**
	 * 通过prepareBulk执行批处理
	 * 
	 * @throws IOException 
	 */
	@Test
	public void testBulk() throws IOException
	{
		//1:生成bulk
		BulkRequestBuilder bulk = transportClient.prepareBulk();
		
		//2:新增
		IndexRequest add = new IndexRequest(index, type, "10");
		add.source(XContentFactory.jsonBuilder()
					.startObject()
					.field("name", "Henrry").field("age", 30)
					.endObject());
		
		//3:删除
		DeleteRequest del = new DeleteRequest(index, type, "1");
		
		//4:修改
		XContentBuilder source = XContentFactory.jsonBuilder().startObject().field("name", "jack_1").field("age", 19).endObject();
		UpdateRequest update = new UpdateRequest(index, type, "2");
		update.doc(source);
		
		bulk.add(del);
		bulk.add(add);
		bulk.add(update);
		//5:执行批处理
		BulkResponse bulkResponse = bulk.get();
		if(bulkResponse.hasFailures())
		{
			BulkItemResponse[] items = bulkResponse.getItems();
			for(BulkItemResponse item : items)
			{
				System.out.println(item.getFailureMessage());
			}
		}
		else
		{
			System.out.println("全部执行成功！");
		}
	}
	
	/**
	 * 通过prepareSearch查询索引库
	 * setQuery(QueryBuilders.matchQuery("name", "jack"))
	 * setSearchType(SearchType.QUERY_THEN_FETCH)
	 * 
	 */
	@Test
	public void testSearch()
	{
		SearchResponse searchResponse = transportClient.prepareSearch(index)
				.setTypes(type)
				.setQuery(QueryBuilders.matchAllQuery()) //查询所有
				//.setQuery(QueryBuilders.matchQuery("name", "tom").operator(Operator.AND)) //根据tom分词查询name,默认or
				//.setQuery(QueryBuilders.multiMatchQuery("tom", "name", "age")) //指定查询的字段
				//.setQuery(QueryBuilders.queryString("name:to* AND age:[0 TO 19]")) //根据条件查询,支持通配符大于等于0小于等于19
				//.setQuery(QueryBuilders.termQuery("name", "tom"))//查询时不分词
				.setSearchType(SearchType.QUERY_THEN_FETCH)
				.setFrom(0).setSize(10)//分页
				.addSort("age", SortOrder.DESC)//排序
				.get();
		
		SearchHits hits = searchResponse.getHits();
		long total = hits.getTotalHits();
		System.out.println(total);
		SearchHit[] searchHits = hits.hits();
		for(SearchHit s : searchHits)
		{
			System.out.println(s.getSourceAsString());
		}
	}
	
	/**
	 * 多索引，多类型查询
	 * timeout
	 */
	@Test
	public void testSearchsAndTimeout()
	{
		SearchResponse searchResponse = transportClient.prepareSearch("shb01","shb02").setTypes("stu","tea")
			.setQuery(QueryBuilders.matchAllQuery())
			.setSearchType(SearchType.QUERY_THEN_FETCH)
			.setTimeout("3")
		    .get();
		
		SearchHits hits = searchResponse.getHits();
        long totalHits = hits.getTotalHits();
        System.out.println(totalHits);
        SearchHit[] hits2 = hits.getHits();
        for(SearchHit h : hits2)
        {
        	System.out.println(h.getSourceAsString());
        }
	}
	
	/**
	 * 过滤，
	 * lt 小于
	 * gt 大于
	 * lte 小于等于
	 * gte 大于等于
	 * 
	 */
	@Test
	public void testFilter()
	{
		SearchResponse searchResponse = transportClient.prepareSearch(index)
				.setTypes(type)
				.setQuery(QueryBuilders.matchAllQuery()) //查询所有
				.setSearchType(SearchType.QUERY_THEN_FETCH)
//				.setPostFilter(FilterBuilders.rangeFilter("age").from(0).to(19)
//						.includeLower(true).includeUpper(true))
				.setPostFilter(FilterBuilders.rangeFilter("age").gte(18).lte(22))
				.setExplain(true) //explain为true表示根据数据相关度排序，和关键字匹配最高的排在前面
				.get();
	
		
		SearchHits hits = searchResponse.getHits();
		long total = hits.getTotalHits();
		System.out.println(total);
		SearchHit[] searchHits = hits.hits();
		for(SearchHit s : searchHits)
		{
			System.out.println(s.getSourceAsString());
		}
	}
	
	/**
	 * 高亮
	 */
	@Test
	public void testHighLight()
	{
		SearchResponse searchResponse = transportClient.prepareSearch(index)
				.setTypes(type)
				//.setQuery(QueryBuilders.matchQuery("name", "Fresh")) //查询所有
				.setQuery(QueryBuilders.queryString("name:F*"))
				.setSearchType(SearchType.QUERY_THEN_FETCH)
				.addHighlightedField("name")
				.setHighlighterPreTags("<font color='red'>")
				.setHighlighterPostTags("</font>")
				.get();
	
		
		SearchHits hits = searchResponse.getHits();
		System.out.println("sum:" + hits.getTotalHits());
		
		SearchHit[] hits2 = hits.getHits();
		for(SearchHit s : hits2)
		{
			Map<String, HighlightField> highlightFields = s.getHighlightFields();
			HighlightField highlightField = highlightFields.get("name");
			if(null != highlightField)
			{
				Text[] fragments = highlightField.fragments();
				System.out.println(fragments[0]);
			}
			System.out.println(s.getSourceAsString());
		}
	}
	
	/**
	 * 分组
	 */
	@Test
	public void testGroupBy()
	{
		SearchResponse searchResponse = transportClient.prepareSearch(index).setTypes(type)
				.setQuery(QueryBuilders.matchAllQuery())
				.setSearchType(SearchType.QUERY_THEN_FETCH)
				.addAggregation(AggregationBuilders.terms("group_age")
						.field("age").size(0))//根据age分组，默认返回10，size(0)也是10
				.get();
		
		Terms terms = searchResponse.getAggregations().get("group_age");
		List<Bucket> buckets = terms.getBuckets();
		for(Bucket bt : buckets)
		{
			System.out.println(bt.getKey() + " " + bt.getDocCount());
		}
	}
	
	/**
	 * 聚合函数,本例之编写了sum，其他的聚合函数也可以实现
	 * 
	 */
	@Test
	public void testMethod()
	{
		SearchResponse searchResponse = transportClient.prepareSearch(index).setTypes(type)
				.setQuery(QueryBuilders.matchAllQuery())
				.setSearchType(SearchType.QUERY_THEN_FETCH)
				.addAggregation(AggregationBuilders.terms("group_name").field("name")
						.subAggregation(AggregationBuilders.sum("sum_age").field("age")))
				.get();
		
		Terms terms = searchResponse.getAggregations().get("group_name");
		List<Bucket> buckets = terms.getBuckets();
		for(Bucket bt : buckets)
		{
			Sum sum = bt.getAggregations().get("sum_age");
			System.out.println(bt.getKey() + "  " + bt.getDocCount() + " "+ sum.getValue());
		}
		
	}
	
	
	
}



```

Elasticsearch笔记六之中文分词器及自定义分词器
原创 2016年09月08日 21:45:56 标签：中文分词器 /自定义分词器 /elasticsearch 8073
中文分词器

在lunix下执行下列命令，可以看到本来应该按照中文”北京大学”来查询结果es将其分拆为”北”,”京”,”大”,”学”四个汉字，这显然不符合我的预期。这是因为Es默认的是英文分词器我需要为其配置中文分词器。

curlHTTP://192.168.79.131:9200/shb01/_analyze?pretty=true -d'{"text":"北京大学"}'

Es整合ik不直接用ik官网的工具包，需要将ik工具包封装成es插件才行，这个已经有人封装好了可以在github上下载elasticsearch-analysis-ik

1：在github上下载ik插件源码

https://github.com/medcl/elasticsearch-analysis-ik

2：下载后解压缩在根目录下使用maven对其进行编译。

编译后把target/release目录下的elasticsearch-analysis-ik-1.3.0.zip上传到/usr/local/elasticsearch-1.4.4/plugins/analysis-ik目录下然后使用unzip解压。

把下载的ik插件中config目录下的文件拷贝到/usr/local/elasticsearch-1.4.4/config目录下，这些文件时ik的配置文件，custom是自定义词库文件。

3：修改elasticsearch.yml文件，把ik分词器设置为es的默认分词器

index.analysis.analyzer.default.type:ik
 
4：重启es，注意es中的每个节点都要进行上述配置。

 自定义分词器

1：创建一个dic文件，编码格式必须为utf-8无BOM格式，每个词一行多个词需要换行。




2：将自定义的dic文件上传到/usr/local/elasticsearch-1.4.4/config/custom目录下

 

3：修改ik的配置文件/usr/local/elasticsearch-1.4.4/config/IKAnalyzer.cfg.xml，在其中指定自定义的dic文件。


4：重启es



Elasticsearch笔记七之setting,mapping,分片查询方式
原创 2016年09月08日 23:32:20 标签：Elasticsearch /settings /mappings /setPreference /_shards 7563
setting

通过setting可以更改es配置可以用来修改副本数和分片数。

1：查看，通过curl或浏览器可以看到副本分片信息

curl -XGET http://192.168.79.131:9200/shb01/_settings?pretty

http://192.168.79.131:9200/shb01/_settings?prett



2：修改

不存在索引shb03时可以指定副本和分片，如果shb03已经存在则只能修改副本

curl -XPUT http://192.168.79.131:9200/shb03-d'{"settings":{"number_of_shards":4,"number_of_replicas":2}}'


shb03已经存在不能修改分片

curl -XPUThttp://192.168.79.131:9200/shb03/_settings -d '{"index":{"number_of_replicas":2}}'


mapping

我们在es中添加索引数据时不需要指定数据类型，es中有自动影射机制，字符串映射为string，数字映射为long。通过mappings可以指定数据类型是否存储等属性。

1：查看mapping信息

curl -XGEThttp://192.168.79.131:9200/shb01/_mappings?pretty

http://192.168.79.131:9200/shb01/_mappings?pretty






2：修改，通过mappings还可以指定分词器

操作不存在的索引

curl -XPUT http://192.168.79.131:9200/shb02-d'{"mappings":{"emp":{"properties":{"name":{"type":"string","indexAnalyzer":"ik","searchAnalyzer": "ik"}}}}}'

操作已存在的索引

curl -XPOSThttp://192.168.79.131:9200/crxy/shb02/_mapping-d'{"properties":{"name":{"type":"string","indexAnalyzer":"ik","searchAnalyzer": "ik"}}}'


java操作settings和mappings

[java] view plain copy
/** 
     * settings,mappings 
     * @throws IOException  
     *  
     * org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder; 
     * org.elasticsearch.common.xcontent.XContentBuilder; 
     * org.elasticsearch.common.xcontent.XContentFactory; 
     */  
    @Test  
    public void testSettingsMappings() throws IOException  
    {  
        //1:settings  
        HashMap<String, Object> settings_map = new HashMap<String, Object>(2);  
        settings_map.put("number_of_shards", 3);  
        settings_map.put("number_of_replicas", 1);  
          
        //2:mappings  
        XContentBuilder builder = XContentFactory.jsonBuilder()  
                .startObject()  
                    .field("dynamic", "stu")  
                    .startObject("properties")  
                        .startObject("id")  
                            .field("type", "integer")  
                            .field("store", "yes")  
                        .endObject()  
                        .startObject("name")  
                            .field("type", "string")  
                            .field("store", "yes")  
                            .field("index", "analyzed")  
                            .field("analyzer", "id")  
                        .endObject()  
                    .endObject()  
                .endObject();  
          
        CreateIndexRequestBuilder prepareCreate = transportClient.admin().indices().prepareCreate("shb01");  
        prepareCreate.setSettings(settings_map).addMapping("stu", builder).execute().actionGet();  
    }         
一般在工作中关闭自动映射防止垃圾数据进入索引库，提前定义好索引库的字段信息当有非法的数据进来时会报错。如果不知道字段信息则开启。


分片查询

Es会将数据均衡的存储在分片中，我们可以指定es去具体的分片或节点钟查询从而进一步的实现es极速查询。

1：randomizeacross shards

随机选择分片查询数据，es的默认方式

2：_local

优先在本地节点上的分片查询数据然后再去其他节点上的分片查询，本地节点没有IO问题但有可能造成负载不均问题。数据量是完整的。

3：_primary

只在主分片中查询不去副本查，一般数据完整。

4：_primary_first

优先在主分片中查，如果主分片挂了则去副本查，一般数据完整。

5：_only_node

只在指定id的节点中的分片中查询，数据可能不完整。

6：_prefer_node

优先在指定你给节点中查询，一般数据完整。

7：_shards

在指定分片中查询，数据可能不完整。

8：_only_nodes

可以自定义去指定的多个节点查询，es不提供此方式需要改源码。

 

注：es的数据存放在/usr/local/elasticsearch-1.4.4/data，如果要升级es可先备份此目录

[java] view plain copy
/** 
     * 指定分片 查询 
     */  
    @Test  
    public void testPreference()  
    {  
        SearchResponse searchResponse = transportClient.prepareSearch(index)  
                .setTypes("add")  
                //.setPreference("_local")  
                //.setPreference("_primary")  
                //.setPreference("_primary_first")  
                //.setPreference("_only_node:ZYYWXGZCSkSL7QD0bDVxYA")  
                //.setPreference("_prefer_node:ZYYWXGZCSkSL7QD0bDVxYA")  
                .setPreference("_shards:0,1,2")  
                .setQuery(QueryBuilders.matchAllQuery()).setExplain(true).get();  
          
        SearchHits hits = searchResponse.getHits();  
        System.out.println(hits.getTotalHits());  
        SearchHit[] hits2 = hits.getHits();  
        for(SearchHit h : hits2)  
        {  
            System.out.println(h.getSourceAsString());  
        }  
    }  

Elasticsearch笔记八之脑裂
原创 2016年09月10日 00:18:54 标签：Elasticsearch /脑裂 2555
概述：

  一个正常es集群中只有一个主节点，主节点负责管理整个集群，集群的所有节点都会选择同一个节点作为主节点所以无论访问那个节点都可以查看集群的状态信息。 而脑裂问题的出现就是因为从节点在选择主节点上出现分歧导致一个集群出现多个主节点从而使集群分裂，使得集群处于异常状态。

 一般es集群会在内网部署，也可能在外网部署比如阿里云。

原因：

1：网络原因

内网一般不会出现此问题，可以监控内网流量状态。外网的网络出现问题的可能性大些。

2：节点负载

         主节点即负责管理集群又要存储数据，当访问量大时可能会导致es实例反应不过来而停止响应，此时其他节点在向主节点发送消息时得不到主节点的响应就会认为主节点挂了，从而重新选择主节点。

3：回收内存

         大规模回收内存时也会导致es集群失去响应。

 

所以内网负载的可能性大，外网网络的可能性大。

预防方案：

1：角色分离

         在es集群中配置2到3个主节点并且让它们只负责管理不负责存储，从节点只负责存储。另外从节点禁用自动发现机制并为其指定主节点，在elasticsearch.yml文件中。

主节点：node.master =true   node.data=false

从节点：node.master =false   node.data=ture

         discovery.zen.ping.multicast.enabled:false 

         discovery.zen.ping.unicast.hosts:["host1", "host2:port"]

  

 

2：参数配置

        discovery.zen.ping_timeout:3

       此参数指定从节点访问主节点后如果3秒之内没有回复则默认主节点挂了，我们可以适当的把它改大，改成5到6秒这样可以减少出现脑裂的概率。

       discovery.zen.minimum_master_nodes:1

       该参数的意思是，当具备成为主节点的从节点的个数满足这个数字且都认为主节点挂了则会进行选举产生新的主节点。

       例如：es集群有三个从节点有资格成为主节点，这时这三个节点都认为主节点挂了则会进行选举，此时如果这个参数的值是4则不会进行选举。

       我们可以适当的把这个值改大，减少出现脑裂的概率，官方给出的建议是(n/2)+1,n为有资格成为主节点的节点数node.master=true。

解决方案：

1：如果有原始数据，建议重新创建索引。

2：将es集群关闭，每次只启动一个节点然后查看节点上的数据是否完整关键，找到数据最完整的那个节点先启动它，再启动其他节点，其他节点可先备份data目录后再删除data。

         因为一般情况下es集群中最先启动的节点会成为主节点，而主节点会被默认为数据最全，后续启动的节点会根据主节点的分片来进行同步，所以我们找到数据最全的节点第一个启动它并以此节点为主节点尽量恢复数据。
	 
	 
Elasticsearch笔记九之优化
原创 2016年09月13日 23:44:43 标签：Elasticsearch /java /优化 /极速查询 /setRouting 1352
优化从索引片段，内存设置，副本，分片，日志等方面入手。
1：索引片段
Es运行时会生成很多索引片段，执行查询时会打开这些索引片断。系统会限制打开索引片断的个数一旦超过这个个数限制就无法打开索引片断。我们可以通过命令来查看更改索引片断的限制数量。
索引片断位置
/usr/local/elasticsearch-1.4.4/data/elasticsearch/nodes/0/indices/shb01/0/index

ulimit –a 查看索引片断数量，默认是1024



ulimit -n 32000 更改索引片断数量





如果索引片断太多会影响效率我们可以在es集群空闲时对索引片断进行合并。合并可以通过curl命令和java来实现。
Curl
curl -XPOST http://192.168.79.131:9200/shb01/_optimize?max_num_segments=1

java

[java] view plain copy
/** 
     * 合并索引片段  
     */  
    @Test  
    public void testOptimize()  
    {  
        transportClient.admin().indices().prepareOptimize("shb01", "shb02")  
                .setMaxNumSegments(1).get();  
    }  
curl命令可以在linux中建立一个定时任务每天执行一次，同样java代码也可以建立一个定时器来执行。

2：内存设置
之前介绍过es集群有两种启动方式
第一种是bin目录下bin/ elasticsearch
打开/usr/local/elasticsearch-1.4.4/bin/elasticsearch.in.sh文件修改文件中的两个参数，将
ES_MIN_MEM=256m和ES_MAX_MEM=1g的值改成一样一般设置为可用内存的60%，这样可以避免频繁的内存交换。
另一种是searchwrapper插件方式启动bin/service/ elasticsearch start
打开/usr/local/elasticsearch-1.4.4/bin/service/修改set.default.ES_HEAP_SIZE=1024

另外在es的配置文件中修改bootstrap.mlockall: true，这样禁止内存交换。


3：分片设置
Es将数据存储在多个分片中那么分片的数量就影响到了查询效率。
分片数少了导致分片过大打开一个太大的分片太慢，分片数量过多查询时会打开过多的分片而且还有多台服务器之间的通信问题。所以过多过少都不行，一般情况下分片数量维持在5~20个之间单个分片最大不要超过20G。我们可以根据实际的业务来评估分片数量。
比如我有5个分片，预计3个月会产生100G的数据，那么我们可以每3个月当5个分片达到20G时就重新建立一个索引库。


4：副本设置
副本多了可以增强es集群的安全性提高搜索能力但是也会相应的增加服务器同步数据的压力，一般可以设置2~3个副本即可。
另外当初次建立索引库时需要大量倒入数据时我们可以临时将副本改为0不让其同步数据以减轻服务器压力，倒入完成后通过mappings来更改副本数，这种方式只针对当前索引库后期添加的索引库仍会读取elasticsearch.yml中的副本个数，es重启后仍然会保持之前mappings修改的副本数。


5：删除文档
在es中删除一个文档后不会立即从硬盘中删除只会标记这个文档被删除，lucene会产生一个.del文件，而在检索过程中这个文件还会参与检索只不过在最后会被过滤掉，这样其实也会影响效率，我们可以定期删除这些文件，同合并索引片断一样可以通过curl和java两种方式来执行。
Curl
curl -XPOST http://192.168.79.131:9200/_optimize?only_expunge_deletes=true
Java

[java] view plain copy
/** 
 * 删除.del文件  
 */  
@Test  
public void testOptimizeDel()  
{  
    transportClient.admin().indices().prepareOptimize("shb01", "shb02")  
            .setOnlyExpungeDeletes(true).get();  
}  


6：日志输出
可以调整es的日志级别，es的默认级别是trace，超过500ms就属于慢查询就需要打印日志，一般改为info或error级别。
日志文件/usr/local/elasticsearch-1.4.4/config/logging.yml
ndex.search.slowlog: TRACE, index_search_slow_log_file 将TRACE改为INFO
或者更改elasticsearch.yml文件中对于慢查询的设置
index.search.slowlog.threshold.query.trace: 500ms 


7：单态获取es对象
在java代码中使用单实例的方式来获取org.elasticsearch.client.transport.TransportClient对象。


8：es极速查询
Es将数据存储在不同的分片中，根据文档id通过内部算法得出要将文档存储在哪个分片上，所以在查询时只有指定在对应的分片上进行查询就可以实现基于es的极速查询，但是前提是你需要知道数据在那个分片上。
还可以通过路由参数来设置数据存储在同一个分片中，setRouting(“”)

[java] view plain copy
/** 
     * 路由参数  
     */  
    @Test  
    public void testRoutingInsert()  
    {  
        String source = "{\"name\":\"中山大学l\",\"num\":1800}";  
        IndexResponse indexResponse = transportClient.prepareIndex(index, "stu")  
                .setRouting("student")  
                .setSource(source).get();  
        System.out.println(indexResponse.getVersion());  
    }  
      
    /** 
     * 路由参数  
     */  
    @Test  
    public void testRoutingSearch()  
    {  
        SearchResponse searchResponse = transportClient.prepareSearch(index)  
                .setTypes("stu")  
                .setQuery(QueryBuilders.matchAllQuery())  
                //.setPreference("_shards:0,1,2")  
                .setRouting("student", "teacher")  
                .get();  
          
        SearchHits hits = searchResponse.getHits();  
        SearchHit[] hits2 = hits.getHits();  
        for(SearchHit h : hits2)  
        {  
            System.out.println(h.getSourceAsString());  
        }  
    }  

9：去掉mapping中_all域


	 























